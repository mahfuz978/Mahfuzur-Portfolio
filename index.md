# Data Science Portfolio

Here are some of my best Data Science Projects. I have explored various machine-learning algorithms for different datasets. Feel free to contanct me to learn more about my experience working with these projects.

***
[What other factors besides the number of bedrooms can influence price of a house](https://github.com/mahfuz978/Kaggle-Challenge/blob/main/Final/Mahfuzur_House_Price_Prediction_Project.ipynb)

<img src="images/House_Price_Prediction.jpg?raw=true"/>

**Skills used:** Python, pandas, sklearn, numpy, matplotlib, seaborn

**Project Objective:** Create a linear model using the provided data. The model needs to acquire an accurate final price prediction of a house using the provided features.

**Quantifiable result:** My model was able to acquire a validation score of 92%.
- I used an XGBoost model to achieve the highest score.
- A combinantion of GridSearchCV and my knowledge was used to tune my models.
- I tested with multiple different models.
- Used a pipeline to speed up my models.

[Understanding how policies can be improved for employee benefits](https://github.com/mahfuz978/Mahfuzur-Portfolio/blob/main/Projects/Mahfuzur_K_Means_Project.ipynb)

<img src="images/how-to-find-your-target-audience-header.png?raw=true"/>

<img src="images/Define-and-understand-target-audience.png?raw=true"/>

**Skills used:** Python, sklearn, pandas, numpy, scipy, matplotlib, seaborn

**Project Objective:** Clean and organize the given data. Then, Cluster the data using a clustering algorithm and find a meaning or a message from the data.  

**Quantifiable result:** I was able to get 5 solid clusters.
- I used to the elbow method to certify the clusters.
- During the EDA I was able to reduce a lot of noises.
- I used data that was withing 2 standard deviation.
- I used WCSS algorithm to detrmine the optimal number of clusters.

[Examining the effect of environmental factors and weather on Bike rentals](https://github.com/mahfuz978/Regression-Classification/blob/main/Linear_Regression/Mahfuzur_Rahman_Linear_Regression_Project.ipynb)

<img src="images/seoul-bikes.jpeg?raw=true"/>

**Skills used:** Python, pandas, numpy, matplotlib, plotly

**Project Objective:** Create a linear model and identify what features affects the number of bikes rented.

**Quantifiable result:** I was able to achieve a validation score of 74% using Bagging Model.
- I used the the highest correlated Data.
- I normalized my data in order to achieve a more accurate result.
- The training score was a very high 96%.
- My error margin was also calculated using the proper metrics.

[How a target clients for a particular marketing campaign using many specific features](https://github.com/mahfuz978/Classification-Regression/blob/main/Logistic_Regression/Mahfuzur_Rahman_Logistic_Regression_Project.ipynb)

<img src="images/Classification.png?raw=true"/>

**Skills used:** Python, pandas, matplotlib, seaborn, sklearn, SMOTE

**Project Objective:** Using a vast data/features of bank customers, create a model that would determine which customers are likely to subscribe to a term deposit.

**Quantifiable result:** I was able to get a accuracy score of 90%
- Logistic regression came out to be a very effective model.
- I used a 0.30 test size and it gave me the best results.
- I used a dummies to encode the categoriclas.
- I used SMOTE because the two classes were highly imbalanced.

[Image recognition using Convolutional Neural Network](https://github.com/mahfuz978/Deep-Neural-Network/blob/main/Mahfuzur_Rahman_CNN_project.ipynb)

<img src="images/Convolutional_Neural_Network_to_identify_the_image_of_a_bird.png?raw=true"/>

**Skills used:** Python, tensorflow, keras, numpy

**Project Objective:** Create a model that could look at a picture, and specify if it is a cat or dog.

**Quantifiable result:** I was able to get a accuracy score of 90%.
- I trained the data using 4000 images.
- I used all the proper bulilding steps to build my CNN model.
- I used a the 'sequential' model and it was very effective.
- I used 'adam' as the optimizer and 'binary_crossentropy' for loss for the optimum result.
